{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5da43b8c",
   "metadata": {},
   "source": [
    "![title](./sven-mieke-MsCgmHuirDo-unsplash.png)\n",
    "\n",
    "Banner made from a photo by [Sven Mieke](https:/unsplash.com/@sxoxm?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/photos/MsCgmHuirDo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40191d8",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "### About Dataset  \n",
    "\n",
    "The market research team at AdRight is assigned the task to identify the profile of the typical customer for each treadmill product offered by CardioGood Fitness. The market research team decides to investigate whether there are differences across the product lines with respect to customer characteristics. The team decides to collect data on individuals who purchased a treadmill at a CardioGoodFitness retail store during the prior three months.\n",
    "\n",
    "### The customer variables to study are:\n",
    "- product purchased: TM195, TM498, or TM798\n",
    "- gender\n",
    "- age, in years\n",
    "- education, in years\n",
    "- relationship status: single or partnered\n",
    "- annual household income ($)\n",
    "- average number of times the customer plans to use the treadmill each week\n",
    "- average number of miles the customer expects to walk/run each week\n",
    "- self-rated fitness on an 1-to-5 scale: where 1 is poor shape and 5 is excellent shape. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7fa5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# dataviz with plotly\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "# for quick viz, set backend\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "\n",
    "# few viz are made with sns & mplt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# stats\n",
    "from scipy import stats\n",
    "\n",
    "#from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Import module for k-protoype cluster\n",
    "from kmodes.kprototypes import KPrototypes\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010aa0cf",
   "metadata": {},
   "source": [
    "### First insight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e666f683",
   "metadata": {},
   "source": [
    "Let's look at the first lines of our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337b183c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('CardioGoodFitness.csv')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee283a1",
   "metadata": {},
   "source": [
    "The number of records is very low, such as the number of variables:  \n",
    "__/!\\ beware__: is the dataset really representative of the treadmill users in general ? This is an open question as there are not too many records, a sample which much more lines would be more reliable ! so __don't take that all the following insights for granted...__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1554e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5443e4e",
   "metadata": {},
   "source": [
    "There isn't any missing value (Nan) and the types of each column is appropriate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff75506c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ea64ed",
   "metadata": {},
   "source": [
    "There isn't any duplicated lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570f10be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8266b73d",
   "metadata": {},
   "source": [
    "By looking at the basic statistics, we can see that\n",
    "- all products were bought by people mostly between 18 and 50 years old.\n",
    "- 75% of purchases were made by people below 33.\n",
    "- most of the people use their treadmill around 3 times a week\n",
    "- they are huge disparities in the incomes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2eee6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T.round(1)\n",
    "\n",
    "# if you wish to include qualitative variables:\n",
    "#df.describe(include='all').T.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2dc8cf",
   "metadata": {},
   "source": [
    "### Problem Statement  \n",
    "- Perform descriptive analytics to create a customer profile for each CardioGood Fitness treadmill product line.\n",
    "- Improve the treadmill recommendation based on the customer informations & boost sales.\n",
    "- Get more insights by clustering the customers: find the specificities of each group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495269ec",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "[The goal of EDA](https://businessanalyst.techcanvass.com/objective-of-exploratory-data-analysis/#:~:text=The%20goal%20of%20EDA%20is,extract%20from%20the%20data%20set.) is to allow data scientists to get deep insight into a data set and at the same time provide specific outcomes that could be extracted from the data set. It includes:\n",
    "\n",
    "- List of outliers\n",
    "- Estimates for parameters\n",
    "- Uncertainties for those estimates\n",
    "- List of all important factors\n",
    "- Conclusions or assumptions as to whether certain individual factors are statistically essential\n",
    "- Optimal settings\n",
    "- A good predictive model\n",
    "\n",
    "Here, our analysis will also help us to make recommendation and to understand what are the specificities of the persons who use / buy treadmills.\n",
    "\n",
    "Most of the data visualizations are made with plotly, so that they are dynamic: one can have more infos by hoovering the varisous areas of the plots. The charts can also be manipulated with the following buttons:\n",
    "![title](./plotly_tip.png)\n",
    "\n",
    "## Univariate analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa4179c",
   "metadata": {},
   "source": [
    "Let's start with our target: the products and their quantities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25870222",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(df, x=\"Product\", width=500, height=400, title=\"Product (our target) histogram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb619d2",
   "metadata": {},
   "source": [
    "Nearly half of the product are the TM195. The TM798 is the less represented:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887c43f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.pie(\n",
    "    df.groupby('Product').agg('count')[['Age']].rename(columns={'Age': 'Count'}).reset_index(), \n",
    "    values='Count', \n",
    "    names='Product', \n",
    "    title='Numerical proportion of Products',\n",
    "    width=400\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb1c4a1",
   "metadata": {},
   "source": [
    "There is a number of people considering themselves in an intermediary shape. While very few people think they are in a poor shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00981562",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(df, x=\"Fitness\", width=500, height=400, title=\"Histogram of fitness\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ad8eed",
   "metadata": {},
   "source": [
    "Most of the customers expect to run / walk less than 220 miles in average:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae20e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(df, x=\"Miles\", width=500, height=400, title=\"Histogram of miles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b080bbd2",
   "metadata": {},
   "source": [
    "Now let's look at the number of usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13b8f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(df, x=\"Usage\", width=500, height=400, title=\"Histogram of usages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05680733",
   "metadata": {},
   "source": [
    "Nearly 60% of the customers are partenered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49928780",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.pie(\n",
    "    df.groupby('MaritalStatus').agg('count')[['Age']].rename(columns={'Age': 'Count'}).reset_index(), \n",
    "    values='Count', \n",
    "    names='MaritalStatus', \n",
    "    title='Proportion depending on the marital status',\n",
    "    width=400\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f92b062",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.pie(\n",
    "    df.groupby('Gender').agg('count')[['Age']].rename(columns={'Age': 'Count'}).reset_index(), \n",
    "    values='Count', \n",
    "    names='Gender', \n",
    "    title='Proportion depending on the Gender',\n",
    "    width=400\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91f05b1",
   "metadata": {},
   "source": [
    "## Bivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d521c17a",
   "metadata": {},
   "source": [
    "for the TM798, there far less females using / buying it than males, compared to the other products:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f4eb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(df, x=\"Product\", color=\"Gender\", barmode='group', width=500, height=400,\n",
    "            title=\"Product counts per Gender\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9041a295",
   "metadata": {},
   "source": [
    "The proportion of Single / Partenered people for each product is quite the same :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab276cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(df, x=\"Product\", color=\"MaritalStatus\", barmode='group', width=500, height=400,\n",
    "            title=\"Product counts per marital status\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde405a6",
   "metadata": {},
   "source": [
    "From the histogram below, it seems that:\n",
    "- most of the buyers use their TM between 2 or 4 times a week\n",
    "- the TM195 is mostly bought by the people that use it less.\n",
    "- on the contrary the TM798 is bought by the most frequent users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d35b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(df, x=\"Usage\", color=\"Product\", barmode='group', width=500, height=400,\n",
    "            title=\"Usage counts per Product\")\n",
    "\n",
    "# same code with sns\n",
    "#sns.countplot(data=df, x=\"Usage\", hue=\"Product\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee110e4",
   "metadata": {},
   "source": [
    "From the graph below:\n",
    "- the mean income of the buyers is around 50k\n",
    "- 25% of the buyers earn around 42k & 75% around 54k\n",
    "- There are very few people earning more than 70k, especially women."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438d9cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(df, x=\"Income\", color=\"Gender\",\n",
    "            marginal=\"box\", # or violin, rug\n",
    "            hover_data=df.columns,\n",
    "            width=700, height=400, barmode=\"overlay\", nbins=30\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32d051e",
   "metadata": {},
   "source": [
    "From below graph we can say that\n",
    "- the mean age of the buyers is aroud 26\n",
    "- 25% of the TM users are around 25\n",
    "- 75% of them are around 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5152f099",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(df, x=\"Age\", color=\"Gender\",\n",
    "            marginal=\"box\", # or violin, rug\n",
    "            hover_data=df.columns,\n",
    "            width=700, height=400, barmode=\"overlay\", nbins=30\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a09419",
   "metadata": {},
   "source": [
    "Some of the important conclusions that can be drawn by looking at the resulsts of the histogram below are:\n",
    "\n",
    "- The TM798 is used by people with relatively high incomes\n",
    "- The TM498 is bought by persons with a yearly income ranging from 45 to 55k\n",
    "- while the people with lower incomes tends to use the TM195"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df1469b",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(df, x=\"Income\", color=\"Product\",\n",
    "            marginal=\"box\", # or violin, rug\n",
    "            hover_data=df.columns,\n",
    "            width=700, height=400, barmode=\"overlay\", nbins=30\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd59f2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(df, x=\"Income\", color=\"MaritalStatus\",\n",
    "            marginal=\"box\", # or violin, rug\n",
    "            hover_data=df.columns,\n",
    "            width=700, height=400, barmode=\"overlay\", nbins=30\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf8e3c0",
   "metadata": {},
   "source": [
    "More infos on the histograms' options in plotly here: ['Histograms with Plotly Express: Complete Guide' by Vaclav Dekanovsky](https://towardsdatascience.com/histograms-with-plotly-express-complete-guide-d483656c5ad7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fac7f8",
   "metadata": {},
   "source": [
    "## Multivariate analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c817be87",
   "metadata": {},
   "source": [
    "There is no particular insights that can be seen from a scatter matrix (the code is nonetheless provided if you want to give it a try)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25d0a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.plotting.scatter_matrix(df, alpha=0.2, figsize=(20, 20));\n",
    "\n",
    "#px.scatter_matrix(\n",
    "#    df, \n",
    "#    color=\"Product\",\n",
    "#    height=1000\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a45674",
   "metadata": {},
   "source": [
    "So let's dig a little deeper with various scatter plots :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6998386",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(\n",
    "    df, \n",
    "    x=\"Age\", \n",
    "    y=\"Usage\",\n",
    "    color=\"Gender\",\n",
    "    size='Usage',\n",
    "    width=800\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38c2bec",
   "metadata": {},
   "source": [
    "From the graph below, it seems that\n",
    "- most of the women earns less than men\n",
    "- there is also a positive trend which indicates that as age increases the income also increases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b10a8b6",
   "metadata": {},
   "source": [
    "If you do the same thing with the MaritalStatus, there is no obvious trend that can be shown..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76fe330",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(\n",
    "    df, \n",
    "    x=\"Age\", \n",
    "    y=\"Income\",\n",
    "    color=\"Gender\",\n",
    "    size='Usage',\n",
    "    width=800\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4151dbbd",
   "metadata": {},
   "source": [
    "Let's see it in 3D:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f9230f",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter_3d(\n",
    "    df, \n",
    "    x='Age', \n",
    "    y='Usage', \n",
    "    z='Income',\n",
    "    color='MaritalStatus'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c1438a",
   "metadata": {},
   "source": [
    "The [heatmap](https://stackoverflow.com/questions/66572672/correlation-heatmap-in-plotly) below with a mask on its half informs us on the correlations between the quantitative variables. \n",
    "- the correlation between Miles & fitness is strong\n",
    "- Age is strongly related to Income\n",
    "- Usage is highly correlated to income, fitness and miles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0e13e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr().round(3)\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "df_mask = corr.mask(mask)\n",
    "\n",
    "fig = ff.create_annotated_heatmap(z=df_mask.to_numpy(), \n",
    "                                  x=df_mask.columns.tolist(),\n",
    "                                  y=df_mask.columns.tolist(),\n",
    "                                  \n",
    "                                  # color options # reverse a built-in color scale by appending _r to its name\n",
    "                                  colorscale=px.colors.diverging.RdBu_r,\n",
    "                                  #colorscale=px.colors.sequential.Viridis,\n",
    "                                  #colorscale=px.colors.sequential.Inferno,\n",
    "                                  hoverinfo=\"none\", #Shows hoverinfo for null values\n",
    "                                  showscale=True, ygap=1, xgap=1\n",
    "                                 )\n",
    "\n",
    "fig.update_xaxes(side=\"bottom\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text='Heatmap', \n",
    "    title_x=0.5, \n",
    "    width=500, \n",
    "    height=500,\n",
    "    xaxis_showgrid=False,\n",
    "    yaxis_showgrid=False,\n",
    "    xaxis_zeroline=False,\n",
    "    yaxis_zeroline=False,\n",
    "    yaxis_autorange='reversed',\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "# NaN values are not handled automatically and are displayed in the figure\n",
    "# So we need to get rid of the text manually\n",
    "for i in range(len(fig.layout.annotations)):\n",
    "    if fig.layout.annotations[i].text == 'nan':\n",
    "        fig.layout.annotations[i].text = \"\"\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf5c19a",
   "metadata": {},
   "source": [
    "When looking at the graph below graph, we can confirm that persons with higher income tends to choose more TM798 and with age income increases.   \n",
    "\n",
    "TM498 and TM195 is more or the same across various buyers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8676c57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(\n",
    "    df.groupby(['Age', 'Product']).agg('mean')[['Income']].reset_index(), \n",
    "    x=\"Age\", \n",
    "    y=\"Income\", \n",
    "    color='Product',\n",
    "    #title='Mean Age',\n",
    "    width=800,\n",
    "    height=400\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101174ab",
   "metadata": {},
   "source": [
    "We can also visualize things in 3D - for fun :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647307f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df.groupby(['Fitness', pd.cut(df.Age, bins=5, labels=list(range(5)))])\\\n",
    "    .agg('mean')[['Income']]\\\n",
    "    .reset_index()\\\n",
    "    .pivot(index='Fitness', columns='Age')\n",
    "\n",
    "go.Figure(data=[go.Surface(z=tmp.values)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0165d454",
   "metadata": {},
   "source": [
    "The [sunburst chart](https://plotly.com/python/sunburst-charts/) is a convenient way to gain insights of the proportions depending on varisous criteria: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af965b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df.groupby(['Product', 'Fitness']).agg('mean')[['Income']].rename(columns={'Income': 'Mean Income'}).reset_index()\n",
    "\n",
    "px.sunburst(\n",
    "    tmp,\n",
    "    path=['Product', 'Fitness'], \n",
    "    values='Mean Income',\n",
    "    #color='Income'\n",
    "    width=600,\n",
    "    title='By hoovering you can see the mean income per TM / usages'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c98d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df.groupby(['Product', 'Gender', 'MaritalStatus']).agg('count')[['Age']].rename(columns={'Age': 'Count'}).reset_index()\n",
    "\n",
    "px.sunburst(\n",
    "    tmp,\n",
    "    path=['Product', 'Gender', 'MaritalStatus'], \n",
    "    values='Count',\n",
    "    width=600,\n",
    "    title='The nb of customers per TM / gender / marital status'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c771e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df.groupby(['Product', 'Fitness', 'Miles']).agg('mean')[['Income']].rename(columns={'Income': 'Mean Income'}).reset_index()\n",
    "\n",
    "px.sunburst(\n",
    "    tmp,\n",
    "    path=['Product', 'Fitness', 'Miles'], \n",
    "    values='Mean Income',\n",
    "    width=600,\n",
    "    title='By hoovering you can see the mean income per TM/usages/miles'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7dd54ab",
   "metadata": {},
   "source": [
    "# Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c698510d",
   "metadata": {},
   "source": [
    "In this sections we're going to etablish what are the specifies of each customers' segment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a9a978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_df(_df, product, gender):\n",
    "    \"\"\" prepare & return the dataframe filtered for the product and gender specified in arguments \"\"\"\n",
    "    \n",
    "    # filter by product & gender\n",
    "    _df = _df[(_df.Product == product) & (_df.Gender == gender)]\n",
    "                      \n",
    "    #select only quantitative cols & product\n",
    "    cols = [c for c in _df.columns if _df[c].dtype==\"int64\" or c == 'Product']\n",
    "    _df = _df[cols]\n",
    "\n",
    "    # scale between 0-5\n",
    "    _df[_df.select_dtypes('number').columns] = preprocessing.MinMaxScaler().fit_transform(_df[_df.select_dtypes('number').columns])\n",
    "    _df[_df.select_dtypes('number').columns] = _df[_df.select_dtypes('number').columns] * 5\n",
    "\n",
    "\n",
    "    # choose a type of product and drop this col\n",
    "    #_df = pd.DataFrame(_df[_df.Product == 'TM798'].drop(columns=['Product']).mean()).reset_index()\n",
    "    _df = _df.groupby('Product').agg('mean').round(2).reset_index().drop(columns=['Product'])\n",
    "    _df = _df.T.reset_index()\n",
    "    \n",
    "    # rename cols\n",
    "    _df.columns = ['Feature', 'Mean']\n",
    "\n",
    "    #_df = pd.DataFrame(_df[(_df.Product == product) & (_df.Gender == gender)].drop(columns=['Product']).mean()).reset_index()\n",
    "    return _df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b50522",
   "metadata": {},
   "source": [
    "Let's stat with the characteristics a simple segment of customers (male users of the TM798). For that the [radar chart](https://plotly.com/python/radar-chart/) can be really convenient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70174cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line_polar(\n",
    "    prepare_df(df, 'TM798', 'Male'), \n",
    "    r='Mean', \n",
    "    theta='Feature', \n",
    "    line_close=True, width=400)\n",
    "fig.update_traces(fill='toself')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e51a878",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=1, cols=3, specs=[[{\"type\": \"scatterpolar\"}, {\"type\": \"scatterpolar\"}, {\"type\": \"scatterpolar\"}]])\n",
    "\n",
    "fig.add_trace(go.Scatterpolar(\n",
    "    r=prepare_df(df, 'TM195', 'Male')['Mean'],\n",
    "    dr=1,\n",
    "    theta=prepare_df(df, 'TM195', 'Male')['Feature'],\n",
    "    fill='toself',\n",
    "    name='Product TM195 / Male'),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(go.Scatterpolar(\n",
    "    r=prepare_df(df, 'TM195', 'Female')['Mean'],\n",
    "    theta=prepare_df(df, 'TM195', 'Female')['Feature'],\n",
    "    fill='toself',\n",
    "    name='Product TM195 / Female'),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(go.Scatterpolar(\n",
    "    r=prepare_df(df, 'TM498', 'Male')['Mean'],\n",
    "    theta=prepare_df(df, 'TM498', 'Male')['Feature'],\n",
    "    fill='toself',\n",
    "    name='Product TM498 / Male'),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.add_trace(go.Scatterpolar(\n",
    "    r=prepare_df(df, 'TM498', 'Female')['Mean'],\n",
    "    theta=prepare_df(df, 'TM498', 'Female')['Feature'],\n",
    "    fill='toself',\n",
    "    name='Product TM498 / Female'),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatterpolar(\n",
    "    r=prepare_df(df, 'TM798', 'Male')['Mean'],\n",
    "    theta=prepare_df(df, 'TM798', 'Male')['Feature'],\n",
    "    fill='toself',\n",
    "    name='Product TM798 / Male'),\n",
    "    row=1, col=3\n",
    ")\n",
    "\n",
    "fig.add_trace(go.Scatterpolar(\n",
    "    r=prepare_df(df, 'TM798', 'Female')['Mean'],\n",
    "    theta=prepare_df(df, 'TM798', 'Female')['Feature'],\n",
    "    fill='toself',\n",
    "    name='Product TM798 / Female'),\n",
    "    row=1, col=3\n",
    ")\n",
    "\n",
    "\n",
    "fig.update_layout(height=600, width=900,\n",
    "                  title_text=\"Specificities of males/females users for each product (beware of scales)\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1168473",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.Income < 45000, \"Income group\"] = \"< 45k\"\n",
    "df.loc[df.Income > 55000, \"Income group\"] = \"> 55k\"\n",
    "df['Income group'].fillna(value='45k < & < 55k', inplace=True)\n",
    "px.histogram(df, x=\"Income group\", width=500, height=400, title=\"Count of users per Income category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1472889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "#df.groupby(['Gender', 'Income group']).agg('count')[['Age']].reset_index().rename(columns={'Age': 'Count'})\n",
    "#df.groupby(['Income group', 'Product']).agg('count')[['Age']].reset_index().rename(columns={'Age': 'Count'})\n",
    "\n",
    "# color palettes: https://colorhunt.co/\n",
    "\n",
    "# sankey diagram\n",
    "fig = go.Figure(data=[go.Sankey(\n",
    "    node = dict(\n",
    "        pad = 15,\n",
    "        thickness = 20,\n",
    "        line = dict(color = \"black\", width = 0.5),\n",
    "        label = [\"Male\", \"Female\", \"<45k\", \"[45k, 55k]\", \">55k\", \"TM195\", \"TM498\", \"TM798\"],\n",
    "        color = ['#C4DDFF', '#FFC4DD', '#DEB6AB', '#F8ECD1', '#AC7D88', \n",
    "                 '#187498', '#36AE7C', '#EB5353']\n",
    "\n",
    "    ),\n",
    "    link = dict(\n",
    "    # indices correspond to labels\n",
    "        source = [0,  0,   0,  1,  1,  1,  2,  2, 2,  3,  3, 3,  4,  4, 4],#, 5, 5, 5, 6, 6, 6, 7, 7, 7], \n",
    "        target = [2,  3,   4,  2,  3,  4,  5,  6, 7,  5,  6, 7,  5,  6, 7],\n",
    "        value =  [25, 42, 37, 24, 35, 17, 34, 15, 0, 35, 33, 9, 11, 12, 31],\n",
    "        color = ['#C4DDFF', '#C4DDFF', '#C4DDFF', '#FFC4DD', '#FFC4DD', '#FFC4DD', '#DEB6AB', \n",
    "                  '#DEB6AB', '#DEB6AB', '#F8ECD1', '#F8ECD1', '#F8ECD1', '#AC7D88', '#AC7D88', '#AC7D88']\n",
    "    \n",
    "))])\n",
    "\n",
    "fig.update_layout(title_text=\"Sankey Diagram of the customers depending on their gender, income & product bought\", font_size=10)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697eea75",
   "metadata": {},
   "source": [
    "This concludes the analysis part, the sankey diagram and radare charts can deliver valuables insights in order to gain a better understanding of the treadmills buyers. Now, let's see if we can make clusters of our customers with machine learning models:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf551c5",
   "metadata": {},
   "source": [
    "The dataset is made of 3 categorical variables and many quantitatives ones. The most well-kown clustering model is Kmeans. But it's not suited with qualitative predicators even one-hot encoded, more infos [here](https://stackoverflow.com/questions/56171837/kmodes-vs-one-hot-encoding-kmeans-for-categorical-data) \n",
    "\n",
    "- _Kmeans + one hot encoding will increase the size of the dataset extensively if the categorical attributes have a large number of categories. This will make the Kmeans computationally costly (curse of dimensionality)_: \n",
    "\n",
    "this is not a problem here.\n",
    "\n",
    "- _the cluster means will make no sense since the 0 and 1 are not the real values of the data. Kmodes on the other hand produces cluster modes which are the real data and hence make the clusters interpretable._: \n",
    "\n",
    "this is why we - at first - will use kmeans only on the numerical variables, then K-Prototype (instead of kmodes) with all features (mix of qualitative & quantitative)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17e121d",
   "metadata": {},
   "source": [
    "---   \n",
    "\n",
    "# Clustering with KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ab7d4b",
   "metadata": {},
   "source": [
    "### Principle\n",
    "\n",
    "![title](./kmeans_animation.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eabb2e5",
   "metadata": {},
   "source": [
    "[image source: K-Means Clustering Algorithm on medium by Parth Patel](https://medium.com/@imparth/k-means-clustering-algorithm-34807a7cec71)\n",
    "\n",
    "If k is given, the K-means algorithm can be executed in the following steps:\n",
    "\n",
    "- Partition of objects into k non-empty subsets\n",
    "- Identifying the cluster centroids (mean point) of the current partition.\n",
    "- Assigning each point to a specific cluster\n",
    "- Compute the distances from each point and allot points to the cluster where the distance from the centroid is minimum.\n",
    "- After re-allotting the points, find the centroid of the new cluster formed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3659f86",
   "metadata": {},
   "source": [
    "### Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbbdaef",
   "metadata": {},
   "source": [
    "Check out this excellent post on [medium by Evgeniy Ryzhkov ont the data preparation before kmeans](https://medium.com/@evgen.ryzhkov/5-stages-of-data-preprocessing-for-k-means-clustering-b755426f9932)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289c6d88",
   "metadata": {},
   "source": [
    "- __Numerical variables only__.  \n",
    "\n",
    "K-means uses distance-based measurements to determine the similarity between data points. If you have categorical data, use K-modes clustering, if data is mixed, use K-prototype clustering.\n",
    "- __Data has no noises or outliers__.  \n",
    "\n",
    "K-means is very sensitive to outliers and noisy data. More detail here and here.\n",
    "- __Data has symmetric distribution of variables (it isn’t skewed)__.\n",
    "\n",
    "Real data always has outliers and noise, and it’s difficult to get rid of it. Transformation data to normal distribution helps to reduce the impact of these issues. In this way, it’s much easier for the algorithm to identify clusters.\n",
    "\n",
    "- __Variables on the same scale__\n",
    "\n",
    "have the same mean and variance, usually in a range -1.0 to 1.0 (standardized data) or 0.0 to 1.0 (normalized data). For the ML algorithm to consider all attributes as equal, they must all have the same scale. More detail here and here.\n",
    "\n",
    "- __There is no collinearity (a high level of correlation between two variables)__. \n",
    "\n",
    "Correlated variables are not useful for ML segmentation algorithms because they represent the same characteristic of a segment. So correlated variables are nothing but noise. More detail here.\n",
    "\n",
    "- __Few numbers of dimensions__. \n",
    "\n",
    "As the number of dimensions (variables) increases, a distance-based similarity measure converges to a constant value between any given examples. The more variables the more difficult to find strict differences between instances.\n",
    "\n",
    "_Note: What exactly does few numbers mean? It’s an open question !_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52064667",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26aacedc",
   "metadata": {},
   "source": [
    "1) No high level of correlation & keep only numerical variables (also few nb of dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ff148c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Age', 'Education', 'Income', 'Miles']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74065ec3",
   "metadata": {},
   "source": [
    "2) Missing or duplicated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb291573",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571b1489",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d97851",
   "metadata": {},
   "source": [
    "3) Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27d9547",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_scores = np.abs(stats.zscore(X, nan_policy='omit'))\n",
    "outliers_threshold = 2  # 3 means that 99.7% of the data is saved\n",
    "                        # to get more smooth data, you can set 2 or 1 for this value\n",
    "mask = (z_scores <= outliers_threshold).all(axis=1)\n",
    "X = X[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086e621d",
   "metadata": {},
   "source": [
    "180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a22fbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4470c9",
   "metadata": {},
   "source": [
    "4) Symmetric distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9d4860",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for c in X.columns:\n",
    "#    df[c].plot.hist().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d0998d",
   "metadata": {},
   "source": [
    "5) Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5328f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy for later use\n",
    "X_bak = X.copy()\n",
    "\n",
    "# X alone instead of X[X.columns] returns a np array \n",
    "X[X.columns] = preprocessing.MinMaxScaler().fit_transform(X[X.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16b50f1",
   "metadata": {},
   "source": [
    "### Results  \n",
    "\n",
    "There is no real 'elbow' that can be observed on the graph below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6746052",
   "metadata": {},
   "outputs": [],
   "source": [
    "km_inertias, km_scores = [], []\n",
    "\n",
    "for k in range(2, 11):\n",
    "    km = KMeans(n_clusters=k).fit(X)\n",
    "    km_inertias.append(km.inertia_)\n",
    "    km_scores.append(silhouette_score(X, km.labels_))\n",
    "    \n",
    "px.line(\n",
    "    pd.DataFrame(list(zip(range(2, 11), km_inertias)), columns=['nb_clusters', 'km_inertias']), \n",
    "    x=\"nb_clusters\", \n",
    "    y=\"km_inertias\", \n",
    "    title='Elbow graph / Inertia depending on k',\n",
    "    width=600, height=500\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6865f8e4",
   "metadata": {},
   "source": [
    "The highest score is for k=6, then in second position comes k=4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e26474",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(\n",
    "    pd.DataFrame(list(zip(range(2, 11), km_scores)), columns=['nb_clusters', 'km_scores']), \n",
    "    x=\"nb_clusters\", \n",
    "    y=\"km_scores\", \n",
    "    title='Scores depending on k',\n",
    "    width=600, height=500\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d7fc1d",
   "metadata": {},
   "source": [
    "Let's [plot a kmeans silhouette analysis](https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html): _the silhouette value is a measure of how similar an object is to its own cluster (cohesion) compared to other clusters (separation). The silhouette ranges from −1 to +1, where a high value indicates that the object is well matched to its own cluster and poorly matched to neighboring clusters. If most objects have a high value, then the clustering configuration is appropriate. If many points have a low or negative value, then the clustering configuration may have too many or too few clusters._ (source: [Wikipedia](https://en.wikipedia.org/wiki/Silhouette_(clustering)))\n",
    "\n",
    "The best option for the value of k is not obvious, but according to the silhouette scores our best options would be 3 then 4.\n",
    "Taken into account all the metrics (elbow graph, scores & silhouettes), we'll stick with k=4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e53027",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_n_clusters = [3, 4, 5, 6, 7]\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    # Create a subplot with 1 row and 2 columns\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(13, 5)\n",
    "\n",
    "    # The 1st subplot is the silhouette plot\n",
    "    # The silhouette coefficient can range from -1, 1 but in this example all\n",
    "    # lie within [-0.1, 1]\n",
    "    ax1.set_xlim([-0.1, 1])\n",
    "    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "    # plots of individual clusters, to demarcate them clearly.\n",
    "    ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "\n",
    "    # Initialize the clusterer with n_clusters value and a random generator\n",
    "    # seed of 10 for reproducibility.\n",
    "    clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n",
    "    cluster_labels = clusterer.fit_predict(X)\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    print(\n",
    "        \"For n_clusters =\", n_clusters,\n",
    "        \"The average silhouette_score is :\", silhouette_avg,\n",
    "    )\n",
    "\n",
    "    # Compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in range(n_clusters):\n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        # cluster i, and sort them\n",
    "        ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "        ax1.fill_betweenx(\n",
    "            np.arange(y_lower, y_upper),\n",
    "            0,\n",
    "            ith_cluster_silhouette_values,\n",
    "            facecolor=color,\n",
    "            edgecolor=color,\n",
    "            alpha=0.7,\n",
    "        )\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "    # 2nd Plot showing the actual clusters formed\n",
    "    colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n",
    "    ax2.scatter(\n",
    "        X.iloc[:, 0], X.iloc[:, 1], marker=\".\", s=30, lw=0, alpha=0.7, c=colors, edgecolor=\"k\"\n",
    "    )\n",
    "\n",
    "    # Labeling the clusters\n",
    "    centers = clusterer.cluster_centers_\n",
    "    # Draw white circles at cluster centers\n",
    "    ax2.scatter(\n",
    "        centers[:, 0],\n",
    "        centers[:, 1],\n",
    "        marker=\"o\",\n",
    "        c=\"white\",\n",
    "        alpha=1,\n",
    "        s=200,\n",
    "        edgecolor=\"k\",\n",
    "    )\n",
    "\n",
    "    for i, c in enumerate(centers):\n",
    "        ax2.scatter(c[0], c[1], marker=\"$%d$\" % i, alpha=1, s=50, edgecolor=\"k\")\n",
    "\n",
    "    ax2.set_title(\"The visualization of the clustered data.\")\n",
    "    ax2.set_xlabel(\"Feature space for the 1st feature\")\n",
    "    ax2.set_ylabel(\"Feature space for the 2nd feature\")\n",
    "\n",
    "    plt.suptitle(\n",
    "        \"Silhouette analysis for KMeans clustering on sample data with n_clusters = %d\"\n",
    "        % n_clusters,\n",
    "        fontsize=14,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b65ad62",
   "metadata": {},
   "source": [
    "In order to visualize the clusters property in a 3D space, let's retrain our model with the our best bet value of k and plot a scatter :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca431daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_clusters = 4\n",
    "km = KMeans(n_clusters=nb_clusters).fit(X)\n",
    "\n",
    "# K-Means visualization on pair of 2 features\n",
    "#plt.figure(figsize=(10, 6))\n",
    "#sns.scatterplot(X.iloc[:, 1], X.iloc[:, 2], hue=km.labels_)\n",
    "#plt.show()\n",
    "\n",
    "# Definition of customers profiles corresponding to each clustersPermalink\n",
    "# Profiles of customers\n",
    "X['label'] = km.labels_\n",
    "#X.label.value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e367c23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter_3d(\n",
    "    X, \n",
    "    x='Age', \n",
    "    y='Education', \n",
    "    z='Income',\n",
    "    color='label',\n",
    "    opacity=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9e6da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# description of each cluster\n",
    "for k in range(nb_clusters):\n",
    "    print(f'cluster nb : {k+1}')\n",
    "    print(X_bak[X.label == k].describe().round(0).astype(int).iloc[[0, 1, 3, 7], :-1])\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152aa8b4",
   "metadata": {},
   "source": [
    "---  \n",
    "\n",
    "# Clustering with K-Prototype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26842ed5",
   "metadata": {},
   "source": [
    "## Principle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114e6151",
   "metadata": {},
   "source": [
    "[Source / Reference: Audhi Aprilliant](https://towardsdatascience.com/the-k-prototype-as-clustering-algorithm-for-mixed-data-type-categorical-and-numerical-fe7c50538ebb)\n",
    "\n",
    "- K-Means is calculated using the Euclidian distance that is only suitable for numerical data. \n",
    "- While K-Mode is only suitable for categorical data only, not mixed data types.\n",
    "- K-Prototype was created to handle mixed data types (numerical and categorical variables). This clustering method is based on partitioning. It's an improvement of both the K-Means and K-Mode models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cdb611",
   "metadata": {},
   "source": [
    "The K-Prototype clustering algorithm in kmodes module needs categorical variables or columns position in the data. This task aims to save those in a given variables cat_cols_positions. It will be added for the next task in cluster analysis. The categorical column position is in the first four columns in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76689946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the position of categorical columns\n",
    "cat_cols_positions = [df.columns.get_loc(col) for col in list(df.select_dtypes('object').columns)]\n",
    "print('Categorical columns           : {}'.format(list(df.select_dtypes('object').columns)))\n",
    "print('Categorical columns position  : {}'.format(cat_cols_positions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce40482",
   "metadata": {},
   "source": [
    "\n",
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea954406",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_scores = np.abs(stats.zscore(df.select_dtypes('number'), nan_policy='omit'))\n",
    "outliers_threshold = 2  # 3 means that 99.7% of the data is saved\n",
    "                        # to get more smooth data, you can set 2 or 1 for this value\n",
    "mask = (z_scores <= outliers_threshold).all(axis=1)\n",
    "df = df[mask]\n",
    "\n",
    "# backup of the data for later\n",
    "df_bak = df.copy()\n",
    "\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a948259",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = list(df.select_dtypes('number').columns) \n",
    "df[num_cols] = preprocessing.MinMaxScaler().fit_transform(df[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c974a2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ea49e4",
   "metadata": {},
   "source": [
    "Next, convert the data from the data frame to the matrix. It helps the kmodes module running the K-Prototype clustering algorithm. Save the data matrix to the variable df_matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1240724c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataframe to matrix\n",
    "df_matrix = df.to_numpy()\n",
    "df_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2831ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3530293f",
   "metadata": {},
   "source": [
    "We are using the Elbow method to determine the optimal number of clusters for K-Prototype clusters. Instead of calculating the within the sum of squares errors (WSSE) with Euclidian distance, K-Prototype provides the cost function that combines the calculation for numerical and categorical variables. We can look into the Elbow to determine the optimal number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d94171f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose optimal K using Elbow method\n",
    "cost, nb_clusters = [], range(2, 10) \n",
    "for cluster in nb_clusters:\n",
    "    try:\n",
    "        kprototype = KPrototypes(n_jobs=-1, n_clusters=cluster, init='Huang', random_state=0)\n",
    "        kprototype.fit_predict(df_matrix, categorical=cat_cols_positions)\n",
    "        cost.append(kprototype.cost_)\n",
    "        print('Cluster initiation: {}'.format(cluster))\n",
    "    except:\n",
    "        break\n",
    "        \n",
    "# Converting the results into a dataframe and plotting them\n",
    "df_cost = pd.DataFrame({'Cluster':nb_clusters, 'Cost':cost})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208eda48",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(\n",
    "    df_cost, \n",
    "    x=\"Cluster\", \n",
    "    y=\"Cost\", \n",
    "    title='Cost depending on k',\n",
    "    width=600, height=500\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e13387f",
   "metadata": {},
   "source": [
    "According to the plot of cost function above, we consider choosing the number of cluster k = 4. But once again, there is no \"real elbow\" here... It will be the optimal number of clusters for K-Prototype cluster analysis. Read more about the Elbow method [here](https://towardsdatascience.com/10-tips-for-choosing-the-optimal-number-of-clusters-277e93d72d92)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7460bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the cluster\n",
    "kprototype = KPrototypes(n_jobs=-1, n_clusters=4, init='Huang', random_state=0)\n",
    "kprototype.fit_predict(df_matrix, categorical=cat_cols_positions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b933cda6",
   "metadata": {},
   "source": [
    "We can print the centroids of cluster using kprototype.cluster_centroids_. For the numerical variables, it will be using the average while the categorical using the mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b57410",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Cluster centorid: {kprototype.cluster_centroids_}\\n\\n\"\n",
    "      f\"Nb of iterations: {kprototype.n_iter_}\\n\\n\"\n",
    "      f\"Cost of the cluster creation: {kprototype.cost_:.2f}\\n\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a539a995",
   "metadata": {},
   "source": [
    "The interpretation of clusters is needed. The interpretation is using the centroids in each cluster. To do so, we need to append the cluster labels to the raw data. Order the cluster labels will be helpful to arrange the interpretation based on cluster labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c8a872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the unscaled values\n",
    "df = df_bak\n",
    "\n",
    "# Add the cluster to the dataframe\n",
    "df['Cluster Labels'] = kprototype.labels_\n",
    "df['Segment'] = df['Cluster Labels'].map({0:'First', 1:'Second', 2:'Third', 3:'Fourth'})\n",
    "\n",
    "# Order the cluster\n",
    "df['Segment'] = df['Segment'].astype('category')\n",
    "df['Segment'] = df['Segment'].cat.reorder_categories(['First','Second','Third', 'Fourth'])\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01efc3c2",
   "metadata": {},
   "source": [
    "To interpret the cluster, for the numerical variables, it will be using the average while the categorical using the mode. But there are other methods that can be implemented such as using median, percentile, or value composition for categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b2496a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster interpretation\n",
    "df.rename(columns = {'Cluster Labels':'Total'}, inplace = True)\n",
    "df.groupby('Segment').agg(\n",
    "    {\n",
    "        'Total':'count',\n",
    "        'Product': lambda x: x.value_counts().index[0],\n",
    "        'Age': lambda x: x.value_counts().index[0],\n",
    "        'Gender': lambda x: x.value_counts().index[0],\n",
    "        'MaritalStatus': lambda x: x.value_counts().index[0],\n",
    "        'Education': 'mean',\n",
    "        'Usage': 'mean',\n",
    "        'Fitness': 'mean',\n",
    "        'Income': 'mean',\n",
    "        'Miles': 'mean'\n",
    "    }\n",
    ").round(1).reset_index().set_index('Segment')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6ed0f1",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877e856f",
   "metadata": {},
   "source": [
    "We have use 2 different approaches to gain insights of the TM customers:\n",
    "- first, after an advanced analysis of the various features, we were able to categorize customers, especially depending of the product bought with the radare charts\n",
    "- then, we've used the kmeans and kprototypes clustering models: it seems that the later is more accurate. The kprototype clusters take into account all the variables even the  categorical ones. The last output just above this conclusion shows the specifities of each clusters. It can be really valuable for marketing or CRM purposes.\n",
    "\n",
    "We could also have tried the Dbscan clustering model (with a dendogram). It can also be informative (but it will be for a later)...  \n",
    "\n",
    "I hope you've enjoyed this study and thank you for reading it :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7648a869",
   "metadata": {},
   "source": [
    "## References:\n",
    "- [Correlation heatmap with plotly](https://stackoverflow.com/questions/66572672/correlation-heatmap-in-plotly)\n",
    "- [CardioGood - Descriptive Statistics & Probability by MAYANK](https://www.kaggle.com/code/mayank2896/cardiogood-descriptive-statistics-probability#Univariate-Analysis)\n",
    "- ['Histograms with Plotly Express: Complete Guide' by Vaclav Dekanovsky](https://towardsdatascience.com/histograms-with-plotly-express-complete-guide-d483656c5ad7)\n",
    "- [Cardio Visualization by NIMA JEHAN](https://www.kaggle.com/code/nimajehan/cardio-visualization)\n",
    "- [Data preparation requirements before kmeans by Evgeniy Ryzhkov](https://medium.com/@evgen.ryzhkov/5-stages-of-data-preprocessing-for-k-means-clustering-b755426f9932)\n",
    "- [Kmodes vs one-hot encoding kmeans for categorical data](https://stackoverflow.com/questions/56171837/kmodes-vs-one-hot-encoding-kmeans-for-categorical-data)\n",
    "- [K-Means Clustering Algorithm image animation on medium by Parth Patel](https://medium.com/@imparth/k-means-clustering-algorithm-34807a7cec71)\n",
    "- [Plot kmeans silhouette analysis](https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html)\n",
    "- [The k-prototype as Clustering Algorithm for Mixed Data Type (Categorical and Numerical) by Audhi Aprilliant](https://towardsdatascience.com/the-k-prototype-as-clustering-algorithm-for-mixed-data-type-categorical-and-numerical-fe7c50538ebb)\n",
    "- [Export animated plotly charts](https://stackoverflow.com/questions/55460434/how-to-export-save-an-animated-bubble-chart-made-with-plotly)\n",
    "\n",
    "I also recommend the excellent [blog post on K-prototypes by Anton Ruberts](https://antonsruberts.github.io/kproto-audience/)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
